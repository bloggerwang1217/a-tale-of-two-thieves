\documentclass[11pt,a4paper]{article}

% for Chinese
\usepackage{fontspec}                    % Allows setting fonts
\usepackage[BoldFont, SlantFont]{xeCJK}  % Set Chinese and English fonts separately
\setCJKmainfont{BiauKaiTC-Regular}        % Set the Chinese font (e.g., BiauKai), English font remains the TeX default

\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage[square,numbers]{natbib}
\usepackage{textcomp}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{fullpage}
\usepackage{authblk}
\usepackage{url}
\usepackage{color}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}

\renewcommand{\baselinestretch}{1.4}

\parskip=5pt
\parindent=20pt
\footnotesep=5mm

\newenvironment{enumerateTight}{\begin{enumerate}\vspace{-8pt}}{\end{enumerate}\vspace{-8pt}}
\newenvironment{itemizeTight}{\begin{itemize}\vspace{-8pt}}{\end{itemize}\vspace{-8pt}}
\leftmargini=25pt      % default: 25pt
\leftmarginii=12pt     % default: 22pt

\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}

\graphicspath{{img/}}

% --- Additional Packages ---
\usepackage[T1]{fontenc}
\usepackage{lmodern}         % For clean font
\usepackage{caption}         % For table captions
\usepackage[margin=1in]{geometry} % Set 1-inch margins
\usepackage{tabularx}        % For flexible width tables (used for Invoice)
\usepackage{ragged2e}        % For \RaggedRight (used in Executive Summary)
\usepackage{enumitem}        % For customizing lists (used for Variables)
\usepackage{float}           % For [H] table placement to keep them in order
\usepackage{calc}            % For \widthof
\usepackage{xcolor}          % For fill-in boxes in invoice
\usepackage{array}           % 用於增強表格功能
\usepackage[colorlinks=true, urlcolor=black, linkcolor=black, citecolor=black]{hyperref}

% --- DOCUMENT START ---
\begin{document}
	
% --- Define a command for the fill-in boxes (put this in your preamble) ---
% 如果您不想放在 preamble，放在 \begin{figure} 之前也可以
	\newcommand{\fillbox}[1]{\fcolorbox{black}{white}{\parbox[c][0.7em][c]{#1}{\strut}}}
	
	% ======================================================
	% 1. INVOICE (Based on Sample Image 3)
	% ======================================================
	\begin{figure}[H]
		\centering
		\renewcommand{\arraystretch}{1.2} % 增加行距，使其不擁擠
		\small
		% 我們使用一個巨大的、只有一欄的 tabular 來當作「外框」
		\begin{tabular}{|p{0.9\textwidth}|} % 這一行定義了最外層的左右框
			\hline % 這一行定義了最外層的上框
			
			% --- 頂部標題 ---
			\multicolumn{1}{|c|}{ % 一個置中的儲存格
				\begin{tabular}{c} % 內部再放一個小表格來放標題
					\textbf{STATISTICAL CONSULTING PROGRAM} \\
					\textit{SCP Letterhead Information}
				\end{tabular}
			} \\
			
			% --- "INVOICE" 標題框 ---
			\multicolumn{1}{|c|}{ % 一個置中的儲存格
				\fbox{\strut\hspace{2em}\textbf{INVOICE}\hspace{2em}} % \fbox 畫出內框
			} \\
			
			% --- 日期/客戶資訊 ---
			\multicolumn{1}{|l|}{ % 一個靠左的儲存格
				% 使用 tabular* 讓 Date/Client 和 Project/Consultant 左右對齊
				\begin{tabular*}{\linewidth}{@{}l@{\extracolsep{\fill}}l@{}}
					Date: November 5, 2025 & Client: NTU Pharmaceutical Manufacturing \\
					Consultant: Min-Hsing Wang & Project: Sampling Method Comparison \\
				\end{tabular*}
			} \\
			\hline % 主要內容區的上邊線
			
			% --- 主要內容區 (這格裡面再放一個三欄式表格) ---
			\multicolumn{1}{|l|}{
				\begin{tabular*}{\linewidth}{@{}p{0.6\linewidth}|r|r@{}} % p{width}|r|r
					\textbf{Services} & \textbf{Hours} & \textbf{Amount} \\
					\hline
					\noalign{\vspace{0.3em}} % 在線條和文字間增加一點空間
					
					% --- Subcontracted ---
					\textbf{Subcontracted:} & & \\
					\quad Data Preparation & 1 & \$200 \\
					\quad Statistical Computing & 2 & \$400 \\
					\quad Documentation of Results & 3 & \$600 \\
					\noalign{\vspace{0.3em}}
					\hline
					\noalign{\vspace{0.3em}}
					% 使用 \fillbox 指令來畫空白框
					\textbf{Subcontract Total @} \$200 \textbf{per hour} & \textbf{6} & \textbf{\$1,200} \\
					\noalign{\vspace{0.5em}}
					
					% --- SCP Consultant ---
					\textbf{SCP Consultant:} & & \\
					\quad Statistical Analysis & 8 & \$1,600 \\
					\quad Report Preparation & 6 & \$1,200 \\
					\quad Visualization & 4 & \$800 \\
					\noalign{\vspace{0.3em}}
					\hline
					\noalign{\vspace{0.3em}}
					\textbf{SCP Consultant Total @} \$200 \textbf{per hour} & \textbf{18} & \textbf{\$3,600} \\
					\noalign{\vspace{0.3em}}
					\hline
					\noalign{\vspace{0.3em}}
					
					% --- Contract Total ---
					\textbf{SCP Contract Total} & \textbf{24} & \textbf{\$4,800} \\
					\noalign{\vspace{0.3em}}
					
				\end{tabular*}
			} \\ % 結束主要內容區
			\hline % 這一行定義了最外層的下框
		\end{tabular} % 結束最外層的表格
		
		\renewcommand{\arraystretch}{1.0} % 把行距設定改回來
		\caption{The Invoice of This Program}
		\label{fig:invoice}
	\end{figure}
	
	\clearpage
	
% ======================================================
% 2. TITLE PAGE (Based on Sample Image 4)
% ======================================================
\begin{titlepage}
	\centering % 頁面內容置中
	\vspace*{2cm} % 頂部留白
	
	{\Large \textbf{Statistical Analysis of Pharmaceutical Sampling Methods}}
	
	\vspace{1.5cm}
	
	% --- 僅針對長標題加框 ---
	\fbox{
		\parbox{0.85\textwidth}{ % 讓文字在 85% 頁寬的方塊內自動換行
			\vspace{0.5em} % <<< 增加上方的空間
			\centering\large
			A Comparative Study of Intermediate Dose and Unit Dose 
			Sampling Instruments for Pharmaceutical Blender Content 
			Uniformity Assessment
			\vspace{0.5em} % <<< 增加下方的空間
		}
	}
	
	\vspace{2.5cm}
	
	Report prepared for NTU Pharmaceutical Manufacturing Quality Assurance
	
	\vspace{0.5cm}
	
	by
	
	\vspace{0.5cm}
	
	Min-Hsing Wang \\
	Statistical Consulting Program
	
	\vspace{2cm}
	
	November 5, 2025
	
	\vfill % 彈性空白，將後續內容推到頁底
	
	% --- Executive Summary (靠左並加底線) ---
	\begin{flushleft}
		\textbf{\Large Executive Summary}
		\rule{\linewidth}{0.5pt} % 在 "Executive Summary" 下方畫一條線
		\vspace{0.3cm}
		
		\RaggedRight % 內文使用靠左對齊 (不左右對齊)
		This report analyzes two pharmaceutical sampling instruments, the Intermediate Dose (INTM) and Unit Dose (UNIT) thieves, to identify critical sources of product variability. While both methods produce statistically equivalent average results (p = 0.307), the INTM thief demonstrates far superior precision with a residual variance 4.81 times lower, making it the recommended tool for reliable quality control. More critically, the analysis reveals that the choice of instrument is secondary to fundamental manufacturing process flaws. The dominant source of product variability is a severe lack of mixture uniformity within the V-Blender, which accounts for 31.05\% of total variance. Furthermore, a systematic loss of approximately 3\% of the active ingredient occurs during the powder-to-tablet compression stage. Therefore, while adopting the INTM thief is advised, it is imperative that future process improvement efforts be prioritized on correcting these two core issues—blending uniformity and compression loss—to ensure final product quality.
	\end{flushleft}
	
	\vspace{1cm} % 頁底留白
	
\end{titlepage}

\clearpage

\tableofcontents
\clearpage
\setcounter{tocdepth}{2}

% ======================================================
% 3. MAIN REPORT BODY
% ======================================================

% --- SECTION 1 (from Page 1 and 4) ---
\section{Introduction}

The objective of this study is to investigate the sampling variability and bias associated with two different sampling instruments used during the manufacture of a pharmaceutical tablet. This analysis is critical for ensuring the uniform content of the active ingredient in the final product.

\subsection{Study Design}

\noindent\textbf{Manufacturing Process:}
The tablets are manufactured by mixing active and inactive ingredients in a ``V-Blender.'' After blending, the powder is discharged and compressed into tablets. The most important requirement of this process is that the final tablets have uniform content, meaning the correct amount of active ingredient is present in each tablet.

\noindent\textbf{Sampling Instruments (The ``Two Thieves''):}
To assess the uniformity of the mixture \textit{before} it is compressed, a ``thief'' instrument is used to obtain samples from different locations within the V-blender. This study compares two types of thieves:

\begin{enumerate}
	\item \textbf{Unit Dose Thief:} This instrument collects three individual unit dose samples at each sampling location. This involves three separate sampling actions at the same spot.
	\item \textbf{Intermediate Dose Thief:} This instrument collects one large sample at each location. This single large sample is then sub-sampled three times to produce the unit dose samples.
\end{enumerate}

\noindent\textbf{Experimental Procedure:}
The experiment was conducted as follows:

\begin{enumerate}
	\item The powder mixture was blended in the V-Blender for 20 minutes.
	\item The two thieves (Unit Dose and Intermediate Dose) were \textbf{tied together} to ensure they sampled from the exact same position and conditions. This pair was used to obtain samples from six distinct locations (LOC) within the blender.
	\item After thief sampling, the powder was discharged and compressed into tablets, which were loaded into 30 drums.
	\item A benchmark sample was created by randomly selecting 10 of the 30 drums and sampling three tablets from each selected drum.
	\item All samples (from both thieves and the tablets) were subjected to an \textbf{Assay} to determine the amount of active ingredient. The specified (target) assay value is 35 mg/100 mg.
\end{enumerate}

\subsection{Variables}

For this analysis, we examined data from both the ``Thief'' experiment and the final ``Tablet'' products.

\noindent\textbf{Quantitative Measures:}

\begin{description}[leftmargin=!, labelwidth=\widthof{\textbf{Assay (Y)}}]
	\item[Assay (Y)] The response variable. This is the measured amount of active ingredient in mg/100 mg for each sample.
\end{description}

\noindent\textbf{Categorical Factors - For Thief Data:}

\begin{description}[leftmargin=!, labelwidth=\widthof{\textbf{METHOD}}]
	\item[METHOD] The sampling instrument used: INTM (Intermediate Dose Thief) or UNIT (Unit Dose Thief)
	\item[LOC] The sampling location within the V-Blender: 1, 2, 3, 4, 5, 6
	\item[REP] The replicate sample taken at each location: 1, 2, 3
\end{description}

\noindent\textbf{Categorical Factors - For Tablet Data:}

\begin{description}[leftmargin=!, labelwidth=\widthof{\textbf{DRUM}}]
	\item[DRUM] Randomly selected drums (10 out of 30 total drums)
	\item[TABLET] Individual tablet samples per drum: 1, 2, 3 (three tablets sampled from each drum)
\end{description}

% --- SECTION 2 (from Page 4-5) ---
\section{Methodology}

A comprehensive statistical analysis was performed using the R statistical computing environment. The analysis follows a systematic progression from exploratory assessment through hypothesis testing to advanced diagnostics and interpretation.

\subsection{Exploratory Data Analysis}

Initial data exploration was conducted to assess data quality and identify patterns:
\begin{itemize}
	\item Summary statistics (mean, median, standard deviation, quartiles) for the Assay outcome by METHOD and LOC
	\item Parallel boxplots and location-specific comparisons to visualize method differences and location effects
\end{itemize}

\subsection{Mixed-Effects Model: Comparing Sampling Methods}

This experiment involves both fixed and random factors, requiring \textbf{mixed-effects model analysis}. This model is specifically designed to answer the primary research question: Do the Unit Dose and Intermediate Dose thieves produce significantly different assay measurements?

\noindent\textbf{Model Specification}:

The model includes a fixed effect for METHOD, random intercepts for LOCATION, and heterogeneous variance structure allowing different residual standard deviations for each sampling method.

\begin{equation}
\text{ASSAY}_{ijk} = \mu + \beta \cdot \text{METHOD} + b_i + \varepsilon_{ijk}
\end{equation}

Where:
\begin{itemize}
	\item $\mu$ = Grand mean (population average assay)
	\item $\beta \cdot \text{METHOD}$ = Fixed effect for sampling method
	\item $b_i$ = Random intercept for each location $i$
	\item $\varepsilon_{ijk}$ = Error term (method-specific variance)
\end{itemize}

The \textbf{Fixed Effect (METHOD)} [$\text{Var}(\beta \cdot \text{METHOD})$] is specified as fixed because the primary research question addresses whether the Unit Dose and Intermediate Dose thieves produce significantly different assay measurements. Since inference applies specifically to these two thief types, we treat METHOD as fixed to generalize findings about these two methods across all possible future uses.

\noindent\textbf{Random Effect (LOCATION) and Variance Decomposition}:

The six sampling locations are a random sample from all possible locations within the blender. By treating LOCATION as random, we enable \textbf{generalization of findings beyond these six specific locations} to any location that could be sampled from the blender in the future. The location-specific random intercepts [$b_i$] represent batch-level manufacturing conditions and individual deviations from the overall mean $\mu$ at each location. These are not generalizable to future batches but are essential for understanding current batch-specific characteristics and for partitioning the total variability appropriately in the current analysis.

The model partitions total variance into two primary variance components, each corresponding to specific elements of the mathematical model in Equation (1):

\begin{enumerate}
	\item \textbf{Between-Location Variance} [$\text{Var}(b_i)$]: Quantifies the systematic differences in blender composition across the six sampling positions. This variance component reflects how much the location-specific random intercepts $b_i$ deviate from zero, indicating location-to-location heterogeneity in the blender contents. Large between-location variance signals that sampling position is a critical factor in determining assay values.

	\item \textbf{Within-Location Variance (Method-Specific)} [$\text{Var}(\varepsilon_{ijk})$]: Reflects measurement precision specific to each sampling method, modeled through the heterogeneous variance structure. The error term $\varepsilon_{ijk}$ is allowed to have different variance for INTM and UNIT methods ($\sigma^2_{\text{INTM}} \neq \sigma^2_{\text{UNIT}}$), enabling direct comparison of measurement consistency between methods independent of location effects.
\end{enumerate}

This variance decomposition enables us to simultaneously answer critical questions: (1) Do the two sampling methods differ on average? (2) Which source of variation—location or method—is more important? (3) Which method provides more reliable, consistent measurements for quality control purposes?

\noindent\textbf{Heterogeneous Variance Structure (Precision Assessment)}:

A critical aspect of this analysis is to determine whether the two methods differ not only in \textbf{mean} assay values but also in \textbf{precision (variability)}. The model includes method-specific residual variance parameters, allowing each sampling method to have its own variance estimate. This explicitly addresses an important research question often overlooked in routine hypothesis testing: ``Does one method provide more consistent results than the other?''

The relative precision is quantified using the \textbf{variance ratio}:
$$\text{Variance Ratio} =
\frac{\sigma^2_{\text{UNIT}}}{\sigma^2_{\text{INTM}}}$$

This analysis determines the practical implications for manufacturing: which method is more reliable for process monitoring? Even if two methods produce equivalent average results, a method with higher variability may be unsuitable for precise quality control monitoring. The heterogeneous variance analysis identifies which method provides more dependable, consistent measurements for routine use in pharmaceutical manufacturing.

\subsection{Regression Perspective: Fixed and Random Effects Decomposition}

Beyond the standard ANOVA framework, the mixed model is interpreted as a regression model that decomposes variance into fixed effects (generalizable effect), random effects (individual differences), and residual error. The mathematical model specification is identical to that presented in Equation (1), including \textbf{(1) Fixed Effect (METHOD)}, \textbf{(2) Random Effect (LOCATION)}, and \textbf{(3) Residual Error}.

This decomposition structure enables us to answer critical questions about variance allocation: How much total variation in assay measurements is attributable to the choice of sampling method (METHOD)? How much is attributable to the sampling location within the blender (LOCATION)? And how much represents random measurement error independent of either factor?

\noindent\textbf{Marginal and Conditional R\textsuperscript{2} Analysis}:

\begin{itemize}
	\item \textbf{Marginal R\textsuperscript{2}}: Reflects the variance explained by fixed effects (METHOD) alone, representing the proportion of assay variation directly attributable to the sampling instrument choice.
	$$R^2_{\text{Marginal}} = \frac{\text{Var}(\hat{\mu} + \beta \cdot \text{METHOD})}{\text{Var}(\text{ASSAY}_{ijk})}$$

	\item \textbf{Conditional R\textsuperscript{2}}: Reflects the variance explained by both fixed effects (METHOD) and random effects (LOCATION) combined, representing the proportion of variation explained when accounting for location-specific differences.
	$$R^2_{\text{Conditional}} = \frac{\text{Var}(\hat{\mu} + \beta \cdot \text{METHOD} + b_i)}{\text{Var}(\text{ASSAY}_{ijk})}$$

\end{itemize}

The difference between Conditional and Marginal R\textsuperscript{2} quantifies the relative importance of location-specific factors in determining assay variability, providing critical insight into variance component allocation for manufacturing quality control decisions and process improvement prioritization.

\subsection{Interaction Analysis: Does METHOD Effect Vary by Location?}

A fundamental question in this study is whether the difference between sampling methods is \textbf{consistent across all locations} or \textbf{varies in a location-dependent manner}. Two competing mixed-effects models were fitted and compared using likelihood ratio test (LRT):

\noindent\textbf{Model 1 (No Interaction)}: Assumes METHOD effect is uniform across all locations

\begin{equation}
\text{ASSAY}_{ijk} = \mu + \beta \cdot \text{METHOD} + b_i + \varepsilon_{ijk}
\end{equation}

The global METHOD effect applies equally at each sampling position, with the model structure identical to Equation (1).

\noindent\textbf{Model 2 (With Interaction)}: Allows METHOD effect to vary by location (random slopes model)

\begin{equation}
\text{ASSAY}_{ijk} = \mu + (\beta + b_{i,\text{METHOD}}) \cdot \text{METHOD} + b_i + \varepsilon_{ijk}
\end{equation}

\noindent\textbf{Where:}
\begin{itemize}
	\item $\mu$ = Grand mean (population average assay)
	\item $\beta$ = Global fixed METHOD effect
	\item $b_i$ = Random intercept for each location $i$
	\item $b_{i,\text{METHOD}}$ = Location-specific random slope (METHOD effect deviation)
	\item $\varepsilon_{ijk}$ = Error term (method-specific variance)
\end{itemize}

This model enables each location to have its own method-specific response pattern, where $b_{i,\text{METHOD}}$ represents location-specific deviations from the global METHOD effect.

A significant interaction would suggest that the choice of sampling method should potentially be tailored to specific locations within the blender, with some locations potentially favoring one method over the other.

\subsection{Model Assessment and Validation}

\noindent\textbf{Diagnostic Checks}: Q-Q plots, normality testing (Shapiro-Wilk test), residuals vs. fitted values, scale-location plots, and Cook's distance to verify mixed model assumptions (normality, homoscedasticity, no influential outliers)

\noindent\textbf{Effect Size Quantification}: In addition to hypothesis tests, multiple effect size measures are calculated, including Cohen's d (standardized mean difference for METHOD comparison), eta-squared (\(\eta^2\)) representing the proportion of variance explained by METHOD, and omega-squared (\(\omega^2\)) as a bias-corrected variance explained estimate. These effect sizes allow us to answer ``How big is the difference?'' independent of whether it reaches statistical significance.

\noindent\textbf{Mean Comparison and Robustness Analysis for Bias}: Pairwise comparisons between specific groups (INTM vs. UNIT, INTM vs. Tablet, UNIT vs. Tablet) are assessed using Welch's t-test, which does not assume equal variances and is appropriate for comparing group means. For each comparison, we extract the observed t-statistic, degrees of freedom, p-value, and 95\% confidence interval for the mean difference. To verify the robustness and stability of these comparisons and assess for systematic bias, bootstrap resampling was employed. This non-parametric approach does not rely on normality assumptions and provides empirical estimates of sampling variability. A total of 1000 bootstrap resamples of the original data were performed, with recalculation of p-values for key comparisons at each iteration. For each bootstrap sample, we recalculate the mean difference and determine whether the absolute difference exceeds the observed absolute difference. The bootstrap p-value represents the proportion of bootstrap samples with differences as extreme or more extreme than observed. Additionally, we compute bootstrap bias (deviation of bootstrap mean from observed estimate) and standard error to assess whether sample estimates show systematic bias relative to true population parameters.

% --- SECTION 3 (from Page 5) ---
\section{Results}

Summary statistics and results of the statistical analysis are presented in Appendix \ref{app:eda} and Appendix \ref{app:mixed-model}. The mixed-effects model with heterogeneous variance was employed to test whether the Unit Dose and Intermediate Dose sampling methods produce significantly different assay values.

\subsection{Exploratory Data Analysis}

Assay values range from 32.77 to 39.80 mg/100mg (see Table \ref{tab:a1}), indicating substantial non-uniformity in the blended powder. Notably, the interquartile range (IQR) for Unit Dose (3.24) is substantially wider than for Intermediate Dose (1.82), confirming greater inherent variability.

\noindent\textbf{Assay Distributions by Method:} Parallel boxplots reveal comparable distributions for both thief methods (Figure \ref{fig:boxplot}), with overlapping interquartile ranges and similar medians. Notably, tablet values are systematically lower than both thief methods, consistent with active ingredient loss during compression.

\noindent\textbf{Assay Values Across Locations:} Substantial between-location variation is observed, with Location 1 showing notably lower values and Location 6 showing the highest values (see Figure \ref{fig:interaction}). \textit{This finding directly addresses the client's Question 2 regarding evidence of location effects (see Section \ref{sec:q2} for comprehensive analysis).} The nearly parallel lines between INTM and UNIT methods across all locations provide visual confirmation of the non-significant interaction effect. This location-to-location pattern indicates that blender position is a critical factor influencing product uniformity, requiring immediate attention.

\subsection{Mixed-Effects Model Results}

A heterogeneous variance mixed-effects model was fitted to compare the two sampling methods while properly accounting for location-specific effects (see Figure \ref{fig:model-summary} for the R model output summary, Table \ref{tab:a2a} and Table \ref{tab:a2b} for detailed results). The analysis reveals three critical findings:

\noindent\textbf{No Significant Difference in Mean Assay Values}: The METHOD factor is not statistically significant (F(1,29) = 1.081, p = 0.307, 95\% CI: [-1.49, 0.47] mg/100mg), indicating that both sampling methods produce similar average results.

\noindent\textbf{Variance Components Analysis}: To understand the sources of measurement variability, we decomposed the total variance into three components: between-location variation, within-location (residual) variation, and METHOD effect (see Table \ref{tab:a3} for detailed decomposition). This analysis reveals two key findings:

\noindent\textbf{(1) Precision Assessment by Within-Location Variance}: The Intermediate Dose method exhibits substantially lower residual variance (ML estimates: 0.7069 mg\textsuperscript{2}/100mg\textsuperscript{2}) compared to Unit Dose (3.4001 mg\textsuperscript{2}/100mg\textsuperscript{2}), representing a 4.81-fold improvement in measurement precision. This superior consistency is critical for process monitoring and early detection of batch deviations.

\noindent\textbf{(2) Blending Uniformity by Between-Location Variance}: Between-Location variation accounts for 31.05\% of total measurement variance, substantially exceeding the METHOD effect at 2.30\%, establishing V-Blender mixture uniformity as the primary concern. Table \ref{tab:a4} presents detailed location-specific random intercepts, revealing that Location 1 shows significantly lower values (35.01 mg/100mg) while Location 6 exhibits the highest values (37.98 mg/100mg), spanning a 2.96 mg/100mg range. \textit{This result comprehensively answers the client's Question 2 about evidence of location effects, with further discussion in Section \ref{sec:q2}.}

\subsection{Regression Perspective: Fixed and Random Effects Decomposition}

The $R^2$ decomposition reveals the relative contribution of each model component to total assay variability (see Table \ref{tab:b3}):

\begin{itemize}
	\item \textbf{Marginal} $\boldsymbol{R^2} = 2.30\%$: METHOD (fixed effect) explains only 2.30\% of total variance, confirming that instrument choice has minimal impact on assay variability.

	\item \textbf{Conditional} $\boldsymbol{R^2} = 33.36\%$: Combined fixed and random effects explain 33.36\% of total variance. The 31.05\% gap between Conditional and Marginal $R^2$ quantifies the LOCATION random effects contribution---13.5 times larger than the METHOD effect.

	\item \textbf{Residual Error = 66.64\%}: The remaining variance represents within-location measurement variability and random error.
\end{itemize}

This decomposition establishes that blender uniformity (LOCATION effects: 31.05\%) overwhelmingly dominates measurement variability, far exceeding the influence of sampling method choice (2.30\%). Given this substantial importance of LOCATION effects, a critical question naturally arises: Could the METHOD effect vary systematically across different sampling locations? If location-dependent METHOD effects exist, this would indicate that the relative performance of the two sampling instruments depends on where in the blender they are used, suggesting potential interactions between sampling position and instrument type. To investigate this hypothesis, we employ a random slopes model that allows the METHOD effect to vary by location.

\subsection{Interaction Analysis: Does METHOD Effect Vary by Location?}

A random slopes mixed model was
fitted to test whether METHOD effects vary 
across sampling locations. The likelihood ratio test yields p = 0.5456 (see Table \ref{tab:b6}), indicating that location-dependent METHOD effects are not statistically significant. Model selection criteria also favor the simpler uniform-effect model. Therefore, the difference between methods applies consistently across all sampling positions.

While the interaction plot (Figure \ref{fig:interaction}) may visually suggest some variability in METHOD effects across locations, the formal statistical test does not provide evidence for significant location-dependent METHOD effects. This could reflect insufficient statistical power due to the limited sample size (n = 6 observations per location: 2 methods $\times$ 3 replicates), which may not be adequate to detect subtle interaction effects. However, from a practical manufacturing perspective, the observed variability appears insufficient to warrant location-specific method selection strategies, and the simpler uniform METHOD effect model remains appropriate for quality control decision-making.

\subsection{Model Assessment}

\subsubsection{Diagnostic Checks}

Diagnostic checks confirm that mixed model assumptions are reasonably satisfied. The raw data for both Intermediate Dose and Unit Dose methods show normal distributions (Shapiro-Wilk p-values = 0.9794 and 0.3190, respectively), and IQR and Cook's Distance outlier detection identified zero outliers for both methods (see Tables \ref{tab:b1} and \ref{tab:b2}). Residual diagnostic plots confirm that the heterogeneous variance model with method-specific variance components appropriately addresses variance differences between methods (see Figure \ref{fig:diagnostics}). For detailed diagnostic assessment including residual plot interpretations and normality test results on residuals, refer to Appendix B.4. 

\subsubsection{Effect Size Quantification}

Effect size analysis quantifies the practical magnitude of the METHOD difference independent of sample size. The standardized mean difference is Cohen's d = 0.2984 (small effect), with the METHOD factor explaining only 2.3025\% of total assay variance ($\eta^2$) or 0.2797\% ($\omega^2$, bias-corrected) (see Table \ref{tab:a10}). The observed difference of 0.51 mg/100mg represents only 1.46\% of the 35 mg/100mg target specification value, rendering it negligible for manufacturing decision-making.

\subsubsection{Thief-to-Tablet Mean Comparison and Robustness Check for Bias}

A critical quality control finding emerges from comparing the thief sampling measurements to the final tablet assay values. \textit{This analysis could address the client's Question 4 regarding whether thief-sampled values are comparable to tablet values (see Section \ref{sec:q4} for detailed discussion and recommendations).} Pairwise Welch's t-tests reveal that tablet samples show substantially lower mean assay values (35.82 mg/100mg) compared to both thief methods. The Intermediate Dose thief overestimates final product content by 1.09 mg/100mg (p = 0.0118, statistically significant), while the Unit Dose method overestimates by 0.58 mg/100mg (p = 0.2802, not statistically significant) (see Table \ref{tab:a6}).

We leverage Bootstrapping to validate (1000 resamples) the reliability of these p-values. The INTM vs. Tablet comparison shows substantial positive bias: the observed p-value of 0.0118 has a bootstrap mean of 0.0556 (bias = 0.0438, SE = 0.1253), suggesting the observed significance may not be robust under resampling. Similarly, UNIT vs. Tablet shows positive bias: observed p = 0.2802, bootstrap mean = 0.3413 (bias = 0.0610, SE = 0.2986). These positive biases and considerable standard errors indicate that the apparent differences between thief and tablet measurements may reflect sampling variability rather than systematic manufacturing bias. The lower tablet mean (35.82 mg/100mg) compared to the model-estimated grand mean (36.91 mg/100mg) suggests approximately 3\% loss during compression, but this finding requires validation through properly designed paired-sampling studies (see Table \ref{tab:a7} for detailed bootstrap results).

\section{Client Questions Analysis}
\label{sec:client_questions}

This section provides comprehensive answers to the four specific questions posed by the client regarding this case study. Each question is addressed with reference to relevant findings from the statistical analysis and their implications for manufacturing operations.

\subsection{Question 1: Are the assay values generally well behaved?}
\label{sec:q1}

The assay values are generally well behaved and suitable for mixed-effects analysis. This question requires careful evaluation using both traditional and repeated-measures-appropriate methods.

\subsubsection{Traditional Diagnostics}

\noindent\textbf{Normality Assessment:} All three measurement methods---Intermediate Dose (n=18), Unit Dose (n=18), and Tablet (n=30)---show normal distributions with Shapiro-Wilk p-values exceeding 0.30 (see Table \ref{tab:b1}), indicating excellent conformity to normality assumptions.

\noindent\textbf{Outlier Detection:} Conservative outlier identification using the criterion Q3 + 2 $\times$ IQR detected zero outliers for both thief sampling methods (see Table \ref{tab:b2}). This conservative threshold (more stringent than the traditional 1.5 $\times$ IQR) confirms absence of extreme values.

\subsubsection{Repeated Measures Consideration}

As the client correctly notes, thief samples constitute repeated measures: three replicates are taken from each location-method combination. This sampling structure introduces potential within-location correlation, as observations from the same location share common location-specific factors (captured by the random intercept $b_i$ in our mixed model).

Traditional outlier detection methods (Q3 + 2 $\times$ IQR) assume independence and do not account for this hierarchical structure. When observations are correlated within groups, standard errors can be underestimated, potentially affecting outlier identification sensitivity.

\subsubsection{Methods for Correlated Data}

Several procedures are available for outlier detection in repeated measures or mixed-effects contexts. We consider these two methods:

\begin{enumerate}
	\item \textbf{Standardized Residuals from Mixed Model:} Extract residuals accounting for both fixed effects (METHOD) and random effects (LOCATION), then standardize. Observations with $|$residual$| > 3$ are flagged.
	
	\item \textbf{Cook's Distance for Mixed Models:} Identifies influential observations by measuring their impact on fitted values when deleted. Cook's distance combines two components:
	\begin{itemize}
		\item \textit{Residual component:} How extreme is the observation's residual? (similar to standardized residual)
		\item \textit{Leverage component ($h_i$):} How isolated is this observation in the predictor space? High leverage means the observation has disproportionate influence on parameter estimates.
	\end{itemize}
\end{enumerate}

In repeated measures contexts, leverage relates to sample size per group: locations with fewer replicates have higher leverage. Values $> 0.5$ warrant investigation as potentially influential observations.

\subsubsection{Application to Current Data and Conclusion}

We applied standardized residuals and Cook's distance analysis using the fitted mixed-effects model:

\begin{itemize}
	\item \textbf{Standardized Residuals:} Analysis reveals 35 of 36 observations (97.2\%) have standardized residuals within $\pm 2.5$ standard deviations. One observation exhibits a residual slightly exceeding the conventional $\pm 3$ threshold (see Figure \ref{fig:diagnostics} and Table \ref{tab:a5}). This outlier represents a single replicate that deviates from its location-method group mean.

	\item \textbf{Cook's Distance:} Figure \ref{fig:cooks-distance} presents Cook's distance plot. Maximum Cook's distance across all observations is 0.072 (well below the 0.5 threshold), indicating no individual observation exerts undue influence on model estimates. Even the observation with the largest standardized residual has minimal influence (Cook's D = 0.072), confirming model conclusions are robust.
\end{itemize}

The assay values are generally well behaved and suitable for analysis. Both traditional methods and repeated-measures-appropriate diagnostics confirm: (1) Normality across all measurement methods (Shapiro-Wilk p $> 0.3$ for all groups). (2) One outlier detected (1 of 36 observations, 2.8\%) with standardized residual $= -3.551$. (3) Despite the outlier, Cook's distance analysis confirms no observation exerts undue influence (max Cook's D = 0.072 $\ll$ 0.5 threshold).

The single outlier has \textbf{high residual magnitude but low leverage}, resulting in negligible influence on model parameter estimates (Cook's D = 0.072). This demonstrates the value of Cook's distance analysis: the observation is statistically unusual but does not compromise our conclusions about METHOD effects or variance components. The mixed model's robustness to this single outlier validates our analytical approach.

Even when accounting for the repeated-measures correlation structure through mixed-model diagnostics, data quality remains excellent with no concerns that would invalidate the statistical inference. The dataset fully satisfies assumptions for mixed-effects model analysis.

\subsection{Question 2: Is there evidence of a location effect?}
\label{sec:q2}

Strong evidence of location effects exists, with profound implications requiring urgent management attention. Location 1 shows significantly lower assay values of 35.01 mg/100mg (random intercept = -1.64, z = -2.801, p = 0.0051), while Location 6 exhibits the highest values of 37.98 mg/100mg (random intercept = +1.33, z = +2.266, p = 0.0235). The total location-to-location range spans 2.96 mg/100mg, representing 8.46\% of the 35 mg/100mg target specification.

Location-specific variance components account for 31.05\% of total measurement variance (see Section 3.2.2 and Table \ref{tab:a3}), which is 13.5 times greater than the METHOD effect. This establishes unambiguously that V-Blender position is the dominant source of product variability.

\noindent\textbf{Manufacturing Implications and Suggestions:} The location effect provides clear evidence of incomplete mixture homogenization within the blender. The current 20-minute mixing protocol appears insufficient, resulting in a 2.96 mg/100mg location-to-location range (8.46\% of target specification). Management should immediately:

\begin{enumerate}
	\item \textbf{Review mixing time adequacy} (potential primary cause). Conduct validation studies with extended mixing times (e.g., 25, 30, 35 minutes) to establish optimal duration. Given the current 20-minute protocol produces significant location effects (Location 1: 35.01 mg/100mg vs Location 6: 37.98 mg/100mg), incremental increases of 5-minute intervals with multi-location sampling at each duration are recommended.

	\item \textbf{Conduct blender loading level experiments (fill ratio).} V-Blenders typically operate optimally at certain fill capacity. Conduct systematic experiments with varying fill levels (e.g., 40\%, 60\%, 80\%) using multi-location sampling at each level to identify the optimal loading volume that minimizes location-to-location variation.

	\item \textbf{Audit powder loading sequence for ingredient segregation effects.} Evaluate whether current loading sequence (order of active and inactive ingredient addition) contributes to stratification. Consider alternating layering technique or pre-blending of components with similar particle size distributions to minimize segregation during loading.

	\item \textbf{Assess blender geometry for dead spots or stratification patterns,} particularly near the V-junction and at extremities where Location 1 (lowest assay: 35.01 mg/100mg, p = 0.0051) and Location 6 (highest assay: 37.98 mg/100mg, p = 0.0235) sampling points are situated. Conduct tracer studies or flow visualization to identify zones of poor mixing.
	
	\item \textbf{Examine mixer rotation speed, direction, and mechanical integrity.} Verify rotation parameters (RPM) against manufacturer specifications. Inspect for mechanical wear, wobble, or imbalanced rotation that could create preferential flow patterns. Document current rotation speed and compare with optimal operating range specified for this V-Blender model.


\end{enumerate}

\subsection{Question 3: Do tablet data show drum or time effects?}
\label{sec:q3}

Temporal analysis of the tablet data (30 tablets from 10 randomly selected drums) reveals no significant drum or time-dependent effects. Two complementary approaches were employed to assess temporal dependencies: autoregressive AR(1) covariance modeling and Durbin-Watson diagnostic testing.

\textbf{Drum-to-Drum Variance:} Random effects modeling (DRUM as random intercept) reveals a between-drum variance of 0.4394 and within-drum variance of 1.3729, yielding a coefficient of variation of 1.85\% (Table \ref{tab:c1}, Appendix C). This indicates excellent drum-to-drum consistency, contrasting favorably with the higher location-to-location variability (CV = 2.80\%) observed at the blending stage. The tablet compression process maintains uniformity despite inherent blender heterogeneity.

\textbf{Temporal Autocorrelation:} An autoregressive AR(1) covariance structure applied to the temporal sequence reveals weak temporal correlation (autocorrelation coefficient $\rho = 0.251$). The likelihood ratio test comparing AR(1) to an independence model yields p = 0.235 (not significant), indicating the AR(1) structure does not significantly improve model fit (Table \ref{tab:c2}, Appendix C). The Durbin-Watson test further corroborates this finding (DW = 1.565, p = 0.077), showing no statistically significant autocorrelation at the $\alpha=0.05$ level (Table \ref{tab:c3}, Appendix C). While not significant, the p-value is marginal and the DW statistic of 1.565 suggests a tendency towards weak positive autocorrelation.

\noindent\textbf{Methodological Note: AR(1) vs.
	Durbin-Watson Test}

The client inquired whether employing an AR(1) covariance
structure is
equivalent to using the Durbin-Watson test. While both
methods address
first-order autocorrelation, they serve different
purposes:

\begin{itemize}
	\item \textbf{Durbin-Watson Test:} A hypothesis test
	for detecting
	first-order autocorrelation in regression residuals.
	The test statistic
	$DW \in [0, 4]$ with $DW \approx 2$ indicating no
	autocorrelation. This is a
	\textit{diagnostic tool} applied after model fitting.
	
	\item \textbf{AR(1) Covariance Structure:} A
	\textit{modeling approach}
	that explicitly incorporates first-order temporal
	correlation into the
	mixed-effects model framework. This structure
	estimates the autocorrelation
	coefficient ($\rho$) and adjusts standard errors and
	inference accordingly.
\end{itemize}

Durbin-Watson tests
\textit{whether} autocorrelation
exists (post-hoc diagnostic), while AR(1) covariance
structure \textit{models}
the autocorrelation directly within the estimation
framework (a priori modeling).
For our tablet data analysis with potential drum-to-drum
dependence, AR(1)
structure provides more appropriate inference by
accounting for temporal
correlation in parameter estimation.

In our analysis, the estimated autocorrelation
coefficient ($\rho = 0.251$) is
small and non-significant (LRT p = 0.235), confirming that temporal
dependence is negligible.
This result is consistent with the Durbin-Watson test
(DW = 1.565, p = 0.077), which also indicates no significant
autocorrelation.
The AR(1) approach provides the
additional benefit of
robust inference even in the presence of weak
autocorrelation, while the Durbin-Watson test serves as a complementary
diagnostic confirmation.

\subsection{Question 4: Are thief-sampled values comparable to tablet values?}
\label{sec:q4}

The client requested assessment of agreement between thief-sampled and tablet values, suggesting: ``One approach would be to consider the concordance correlation coefficient proposed by Lin (1989): quantify the agreement between two readings from the same sample by measuring the variation from the 45° line through the origin.''

\noindent\textbf{Methodological Note for Lin's CCC:} Lin's concordance correlation coefficient (CCC) \citep{Lin1989} requires paired measurements from the same sample unit to quantify agreement. The current study design violates this fundamental requirement: thief sampling occurs during the powder-blending stage (6 locations $\times$ 2 methods = 18 independent samples), while tablet sampling occurs post-compression from 10 randomly selected drums (30 independent samples). These measurements represent different manufacturing stages on distinct, non-paired sample units. Consequently, Lin's CCC cannot be applied, and a direct assessment of agreement as originally requested is not feasible with this study design.

\noindent\textbf{Alternative Analysis:} In the absence of paired data, we employ Welch's t-test to compare mean assay values between thief and tablet measurements. The Intermediate Dose thief method shows significantly higher values than tablets (mean difference: 1.09 mg/100mg, 95\% CI: [0.258, 1.924], p = 0.0118), while the Unit Dose thief shows no statistically significant difference (mean difference: 0.58 mg/100mg, 95\% CI: [-0.500, 1.660], p = 0.2802) (see Table \ref{tab:a6}).

To assess the reliability of these p-values, we applied bootstrap validation. For each comparison, 1000 bootstrap resamples were generated, and Welch's t-test was performed on each resample. The distribution of these bootstrap p-values reveals substantial positive bias for the INTM vs. Tablet comparison: the observed p-value of 0.0118 has a bootstrap mean of 0.0556 with bias = 0.0438 (see Table \ref{tab:a7}). Such positive bias suggests that ``the significant difference originally observed between the Intermediate Dose Thief and Tablet assay values may not necessarily be valid.'' The bootstrap standard error (0.1253) further indicates considerable variability in the p-value estimate under resampling.

\noindent\textbf{Conclusion:} Bootstrap validation indicates both comparisons are non-significant under resampling, suggesting the observed differences may reflect sampling variability. However, the INTM vs Tablet bootstrap mean (p = 0.0556) remains close to the conventional 0.05 threshold, warranting careful attention. This pattern, coupled with the observed mean difference of 1.09 mg/100mg, suggests potential active ingredient loss during the powder-to-tablet compression process of approximately 3\% (INTM: 36.91 mg/100mg vs Tablet: 35.82 mg/100mg). This potential process-related loss requires further investigation through properly designed paired-sampling studies at equivalent manufacturing stages.


% --- SECTION 5 ---
\section{Conclusions}

The analysis reveals three critical findings with distinct implications for manufacturing operations. First, both sampling methods produce statistically equivalent mean assay results (p = 0.307), with a difference of 0.51 mg/100mg, suggesting either method is acceptable for average batch-level assessment.

Second, the methods differ substantially in measurement precision. The Intermediate Dose method exhibits 4.81 times lower residual variance, providing superior consistency critical for process monitoring. For pharmaceutical manufacturing, measurement precision is typically more important than equivalent means.

Third and most significantly, location-specific effects within the V-Blender are the dominant source of product variability. Location-to-location variation spans 2.96 mg/100mg (35.01 to 37.98 mg/100mg range), accounting for 31.05\% of total measurement variance (substantially exceeding the 2.30\% METHOD effect) and far exceeding the method difference. Location 1 shows significantly lower values while Location 6 is highest, providing clear evidence of non-uniform powder mixing.

Based on these findings, the Intermediate Dose Thief is recommended for all future sampling due to its superior precision. However, the analysis more critically reveals that process-related issues are of far greater importance than the choice of instrument. The primary sources of product variability are a substantial lack of mixture uniformity within the V-Blender and a systematic loss of approximately 3\% of the active ingredient during the powder-to-tablet compression stage. Therefore, future process improvement efforts should be prioritized and focused on these two critical manufacturing areas to enhance final product quality.


% --- REFERENCES (from Page 6) ---
\begin{thebibliography}{99}

\bibitem{Cabrera2002} Cabrera, J., and McDougall, A. (2002) \textit{Statistical Consulting}. Springer-Verlag New York, Inc., ISBN 978-1-4757-3663-2 (eBook).

\bibitem{Lin1989} Lin, L. I.-K. (1989) A Concordance Correlation Coefficient to Evaluate Reproducibility. \textit{Biometrics}, 45(1), 255--268. DOI: 10.2307/2532051.

\end{thebibliography}

\clearpage

% ======================================================
% 4. APPENDIX
% ======================================================
\appendix
\section{Appendix A: Exploratory Data Analysis}
\label{app:eda}

\subsection{Summary Statistics and Data Quality Assessment}

% --- Table A.1 (Summary Statistics) ---
\begin{table}[H]
	\centering
	\caption{Summary Statistics for Assay Value by Method (Including Final Tablets)}
	\label{tab:a1}
	\small
	\begin{tabular}{l rrrrrrrr}
		\toprule
		\textbf{Method} & \textbf{N} & \textbf{Mean} & \textbf{SD} & \textbf{Min} & \textbf{Q1} & \textbf{Median} & \textbf{Q3} & \textbf{Max} \\
		\midrule
		Unit Dose (UNIT) & 18 & 36.40 & 1.98 & 32.77 & 34.74 & 36.74 & 37.98 & 39.16 \\
		Intermediate Dose (INTM) & 18 & 36.91 & 1.40 & 34.38 & 36.01 & 36.67 & 37.83 & 39.80 \\
		Tablet (Final Product) & 30 & 35.82 & 1.33 & 33.09 & 35.10 & 35.69 & 36.52 & 39.44 \\
		\bottomrule
	\end{tabular}
\end{table}

\subsection{Distribution Visualization}

Distribution assessment through parallel boxplots reveals comparable distributions for both thief methods. Figure \ref{fig:boxplot} displays the assay values by method with individual data points shown with jitter for visibility.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\textwidth]{boxplot.png}
	\caption{Boxplot of Assay Values by Method}
	\label{fig:boxplot}
\end{figure}

Figure \ref{fig:interaction} presents an interaction plot showing location-specific assay values for each method. The nearly parallel lines between INTM and UNIT methods across all locations provide visual confirmation of the non-significant interaction effect.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\textwidth]{interaction_plot.png}
	\caption{Interaction Plot - Location-Specific Assay Values}
	\label{fig:interaction}
\end{figure}

\clearpage

\section{Appendix B: Mixed-Effects Model}
\label{app:mixed-model}

\subsection{Model Summary and Fixed Effects Tests}

The mixed-effects model was fitted using R's \texttt{nlme} package with maximum likelihood estimation (ML). The model includes a fixed effect for METHOD, random intercepts for LOCATION, and heterogeneous variance structure allowing different residual standard deviations for each sampling method.

% --- Figure B.1 (Model Summary Output) ---
\begin{figure}[H]
	\centering
	\includegraphics[width=0.85\textwidth]{img/3-2-model_summary.png}
	\caption{R Output: Mixed-Effects Model Summary}
	\label{fig:model-summary}
\end{figure}

% --- Table B.1 (Fixed Effects Estimates) ---
\begin{table}[H]
	\centering
	\caption{95\% Confidence Intervals of the Mixed-Effects Model}
	\label{tab:a2b}
	\small
	\begin{tabular}{l rrrrr}
		\toprule
		\textbf{Effect} & \textbf{Estimate} & \textbf{Std. Error} & \textbf{Lower 95\% CI} & \textbf{Upper 95\% CI} & \textbf{p-value} \\
		\midrule
		(Intercept) & 36.9078 & 0.4665 & 35.9805 & 37.8350 & $<$0.0001 \\
		METHODUnit & -0.5111 & 0.4915 & -1.4880 & 0.4658 & 0.307 \\
		\bottomrule
	\end{tabular}
\end{table}

% --- Table B.1 (Wald F-Test) ---
\begin{table}[H]
	\centering
	\caption{Wald F-Test of Fixed Effects}
	\label{tab:a2a}
	\small
	\begin{tabular}{l rrrr}
		\toprule
		\textbf{Effect} & \textbf{Num DF} & \textbf{Den DF} & \textbf{F-value} & \textbf{p-value} \\
		\midrule
		(Intercept) & 1 & 29 & 6441.024 & $<$0.0001 \\
		METHOD & 1 & 29 & 1.081 & 0.307 \\
		\bottomrule
	\end{tabular}
\end{table}

\subsection{Variance Components (Heterogeneous Variance Model)}

% --- Table A.3 (Variance Components) ---
\begin{table}[H]
	\centering
	\caption{Variance Components Decomposition}
	\label{tab:a3}
	\small
	\begin{tabular}{l rrc}
		\toprule
		\textbf{Variance Component} & \textbf{Estimate} &
		\textbf{Percentage} & \textbf{Interpretation} \\
		\midrule
		Between-Location [$\text{Var}(b_i)$] & 0.9976 & 31.0539\% &
		Location-to-location variability \\
		\midrule
		Within-Location, INTM [$\text{Var}(\varepsilon_{ijk})$] &
		0.7069 & -- & Residual - Intermediate Dose \\
		Within-Location, UNIT [$\text{Var}(\varepsilon_{ijk})$] &
		3.4001 & -- & Residual - Unit Dose \\
		Within-Location, Pooled [$\overline{\text{Var}(\varepsilon_{ijk})}$] & 2.0535
		& 66.6436\% & Weighted average residual \\
		\midrule
		METHOD Effect [$\text{Var}(\beta \cdot \text{METHOD})$] & 0.0672 &
		2.3025\% & Fixed effect variance \\
		\midrule
		\textbf{Total Variance} & \textbf{2.9175} &
		\textbf{100.0\%} & \\
		\bottomrule
	\end{tabular}
	\\ \vspace{0.2cm}
	\footnotesize
	\textbf{Note:} Pooled within-location variance
	calculated as weighted average:
	$(18 \times 0.7069 + 18 \times 3.4001) / 36 = 2.0535$.
	Variance ratio (UNIT/INTM) = 4.81,
	indicating INTM provides substantially superior
	measurement precision. Percentages are based on
	R\textsuperscript{2} decomposition to ensure they sum to 100\%.
	The decomposition shows location effects (31.05\%) dominate
	over method choice (2.30\%), with a 13.5-fold difference.
\end{table}

\subsection{Location Effects Analysis}

% --- Table A.4 (Location Effects) ---
\begin{table}[H]
	\centering
	\caption{Random Effects for Sampling Location with Significance Testing}
	\label{tab:a4}
	\footnotesize
	\begin{tabular}{l rrrrrl}
		\toprule
		\textbf{Loc} & \textbf{Random Intercept} & \textbf{Loc} & \textbf{Relative Deviation (\%)} & \textbf{z-score} & \textbf{p-value} & \textbf{Status} \\
		\midrule
		1 & -1.64 & 35.01 & -4.47 & -2.801 & 0.0051 & Significantly lower \\
		2 & +0.30 & 36.95 & +0.81 & +0.506 & 0.6130 & Not significant \\
		3 & -0.43 & 36.22 & -1.18 & -0.742 & 0.4581 & Not significant \\
		4 & +0.53 & 37.18 & +1.45 & +0.907 & 0.3642 & Not significant \\
		5 & -0.08 & 36.57 & -0.22 & -0.135 & 0.8923 & Not significant \\
		6 & +1.33 & 37.98 & +3.62 & +2.266 & 0.0235 & Marginally higher \\
		\bottomrule
	\end{tabular}
	\\ \vspace{0.2cm}
	\footnotesize
	\textbf{Note:} Due to balanced design (6 observations per location: 2 methods × 3 replicates), all locations share the same standard error: SE = 0.585, calculated as SE = $\sqrt{\sigma^2_{\text{pooled}} / n}$ where $\sigma^2_{\text{pooled}}$ = 2.0535. Z-scores and p-values computed using normal approximation (two-tailed test). ``Relative Deviation'' represents the random intercept as a percentage of the grand mean (36.65 mg/100mg). Location 1 shows statistically significant deviation at $\alpha = 0.01$ level (p = 0.0051). Location 6 shows marginally significant deviation at $\alpha = 0.05$ level (p = 0.0235). Location Range Span: 2.96 mg/100mg (from Location 1 at 35.01 to Location 6 at 37.98).
\end{table}

\subsection{Variance Decomposition: $R^2$ Components}

% --- Table B.3 ($R^2$ Decomposition) ---
\begin{table}[H]
	\centering
	\caption{$R^2$ Decomposition and Variance Component Mapping}
	\label{tab:b3}
	\small
	\begin{tabular}{l r l}
		\toprule
		\textbf{$R^2$ Measure} & \textbf{Value} & \textbf{Interpretation \& Table A.3 Connection} \\
		\midrule
		Marginal $R^2$ (METHOD only) & 2.3025\% & Fixed METHOD effect (see Table A.3, row 5) \\
		Conditional $R^2$ (METHOD + LOCATION) & 33.3564\% & Marginal + Random LOCATION effects \\
		\midrule
		\multicolumn{3}{l}{\textit{Variance Component Decomposition:}} \\
		METHOD Effect & 2.3025\% & $\text{Marginal R}^2$ (Table A.3) \\
		LOCATION Effects & 31.0539\% & $\text{Conditional R}^2 - \text{Marginal R}^2$ \\
		Residual Error & 66.6436\% & $1 - \text{Conditional R}^2$ \\
		\bottomrule
	\end{tabular}
	\\ \vspace{0.2cm}
	\footnotesize
	\textbf{Note:} This table connects the $R^2$ decomposition (hierarchical model variance explained) with Table A.3 (variance components decomposition). Marginal $R^2$ = 2.3025\% represents the variance explained by the fixed METHOD effect alone. Conditional $R^2$ = 33.3564\% includes both fixed and random effects. The additional 31.0539\% explained by LOCATION random intercepts demonstrates that location-specific manufacturing conditions dominate over method choice (13.5-fold ratio).
\end{table}

\subsection{Random Slopes Model Summary}

For testing location-specific METHOD effects (i.e., whether METHOD effect varies across sampling locations), a random slopes model was fitted allowing the METHOD coefficient to vary by location. The model specification includes both random intercepts and random slopes for METHOD.

% --- Figure B.5 (Random Slopes Model Summary Output) ---
\begin{figure}[H]
	\centering
	\includegraphics[width=0.85\textwidth]{img/3-6-model_summary.png}
	\caption{R Output: Random Slopes Mixed-Effects Model Summary (METHOD + Random Slopes by Location)}
	\label{fig:random-slopes-summary}
\end{figure}

% --- Table B.6 (Random Slopes Model Comparison) ---
\begin{table}[H]
	\centering
	\caption{Likelihood Ratio Test: Random Slopes Model vs. Base Random Intercept Model}
	\label{tab:b6}
	\small
	\begin{tabular}{l r r r l r r}
		\toprule
		\textbf{Model} & \textbf{df} & \textbf{AIC} & \textbf{BIC} & \textbf{Test} & \textbf{L.Ratio} & \textbf{p-value} \\
		\midrule
		mixed\_model & 5 & \fbox{138.8111} & \fbox{146.7287} & & & \\
		mixed\_interaction & 7 & 141.5994 & 152.6840 & 1 vs 2 & 1.211742 & 0.5456 \\
		\bottomrule
	\end{tabular}
	\\ \vspace{0.2cm}
	\footnotesize
	\textbf{Note:} Likelihood ratio test comparing base random intercept model (mixed\_model) versus random slopes model (mixed\_interaction). The test statistic L.Ratio = 1.211742 follows a $\chi^2$ distribution with df = 2. The non-significant p-value (0.5456) indicates that the random slopes model does not provide significantly better fit. Model selection criteria (AIC and BIC) also favor the simpler base model.
\end{table}

\subsection{Diagnostic Checks}

Diagnostic checks confirm that mixed model assumptions are reasonably satisfied. Individual method groups (INTM and UNIT) show normal residuals with p-values of 0.7511 and 0.1842 respectively. The heterogeneous variance model with method-specific variance components (varIdent structure) appropriately accounts for variance differences between methods.

\subsubsection{Detailed Diagnostic Assessment}

\noindent\textbf{Normality of Raw Data:} Both the Intermediate Dose and Unit Dose sampling methods show normal distributions with Shapiro-Wilk test p-values well exceeding 0.05 (see Table \ref{tab:b1}), indicating data suitable for parametric analysis.

\noindent\textbf{Outlier Detection:} Conservative outlier identification using the criterion Q3 + 2 $\times$ IQR identified zero outliers for both methods (see Table \ref{tab:b2}), confirming the absence of extreme values that could compromise model validity.

\noindent\textbf{Residual Diagnostics:} Post-model residual assessment reveals several key features (see Figure \ref{fig:diagnostics}):
(1) \textit{Residuals vs. Fitted Values} displays a slight curvature in the trend line with slightly increased scatter in the mid-range of fitted values (36.0--37.5), indicating minor heteroscedasticity where variance differs across fitted value ranges. The residual pattern exhibits some clustering by method, supporting the use of method-specific variance components in the model.
(2) \textit{Normal Q-Q Plot} demonstrates good alignment with the theoretical normal distribution in the central region, with deviations primarily in the lower tail, confirming the Shapiro-Wilk residual test result (W = 0.9290, p = 0.0234). Despite this slight deviation, the heterogeneity is moderate and does not invalidate mixed model inference given the robustness of F-tests to moderate normality violations. The individual method groups show substantially better normality (INTM: W = 0.9676, p = 0.7511; UNIT: W = 0.9287, p = 0.1842), confirming that the combined residual non-normality reflects method-specific variance heterogeneity rather than distributional pathology.

Overall, diagnostic assessments demonstrate that mixed model assumptions are adequately satisfied. The varIdent heterogeneous variance structure appropriately addresses the identified variance differences between methods, and no influential outliers or leverage points compromise the model estimates.

% --- Table B.1 (Normality Tests on Raw Data) ---
\begin{table}[H]
	\centering
	\caption{Normality Tests on Raw Data (Shapiro-Wilk)}
	\label{tab:b1}
	\small
	\begin{tabular}{l r r r r}
		\toprule
		\textbf{Method} & \textbf{n} & \textbf{W-Statistic} & \textbf{p-Value} & \textbf{Status} \\
		\midrule
		Intermediate Dose & 18 & 0.9836 & 0.9794 & Normal $\checkmark$ \\
		Unit Dose & 18 & 0.9424 & 0.3190 & Normal $\checkmark$ \\
		Tablet & 30 & 0.9614 & 0.3354 & Normal $\checkmark$ \\
		\bottomrule
	\end{tabular}
	\\ \vspace{0.2cm}
	\footnotesize
	\textbf{Note:} All three methods show normal distributions with Shapiro-Wilk p-values $>$ 0.05, indicating data are suitable for parametric analysis.
\end{table}

% --- Table B.2 (Outlier Detection) ---
\begin{table}[H]
	\centering
	\caption{Outlier Detection (Q3 + 2 $\times$ IQR criterion)}
	\label{tab:b2}
	\small
	\begin{tabular}{l rrrrrrr}
		\toprule
		\textbf{Method} & \textbf{Q1} & \textbf{Q3} & \textbf{IQR} & \textbf{Upper Bound} & \textbf{Values > UB} & \textbf{Outliers} \\
		\midrule
		Intermediate Dose & 36.01 & 37.83 & 1.82 & 41.47 & None & 0 \\
		Unit Dose & 34.745 & 37.985 & 3.24 & 44.465 & None & 0 \\
		\bottomrule
	\end{tabular}
	\\ \vspace{0.2cm}
	\small Note: Quartile values were computed using R's default quantile() function with type=7 (linear interpolation).
\end{table}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.95\textwidth]{img/diagnostic_plots.png}
	\caption{Residual Diagnostics for Mixed-Effects Model. Left panel: Standardized residuals vs fitted values with LOESS smooth (blue line). Right panel: Normal Q-Q plot with reference line. Points are color-coded by residual magnitude: red ($|$resid$| > 3$), orange ($2.5 < |$resid$| \leq 3$), gray ($|$resid$| \leq 2.5$). Extreme observations are labeled. Both plots confirm model assumptions are adequately satisfied.}
	\label{fig:diagnostics}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.85\textwidth]{img/cooks_distance_plot.png}
	\caption{Cook's Distance for All 36 Observations. Vertical lines represent Cook's distance for each observation, color-coded by magnitude: red (D $> 0.5$, influential), orange ($0.1 < $ D $\leq 0.5$), gray (D $\leq 0.1$). Horizontal reference lines mark the conventional influence thresholds at D = 0.5 (dashed red) and D = 1.0 (dashed dark red). All observations fall well below the D = 0.5 threshold (max D = 0.072), confirming no individual observation exerts undue influence on model parameter estimates.}
	\label{fig:cooks-distance}
\end{figure}

% --- Table A.5 (Residual Diagnostics) ---
\begin{table}[H]
	\centering
	\caption{Normality Tests on Residuals (Shapiro-Wilk)}
	\label{tab:a5}
	\small
	\begin{tabular}{l rrr}
		\toprule
		\textbf{Group} & \textbf{W-statistic} & \textbf{p-value} & \textbf{Result} \\
		\midrule
		All residuals combined & 0.9290 & 0.0234 & $\times$ Non-Normal \\
		INTM method residuals & 0.9676 & 0.7511 & $\checkmark$ Normal \\
		UNIT method residuals & 0.9287 & 0.1842 & $\checkmark$ Normal \\
		\bottomrule
	\end{tabular}
\end{table}

\subsection{Effect Size Calculations}

% --- Table A.10 (Effect Size Measures) ---
\begin{table}[H]
	\centering
	\caption{Effect Size Measures for METHOD Comparison}
	\label{tab:a10}
	\small
	\begin{tabular}{l rrr}
		\toprule
		\textbf{Measure} & \textbf{Value} & \textbf{Formula} & \textbf{Interpretation Benchmark} \\
		\midrule
		Cohen's d & 0.2984 & $\frac{M_1 - M_2}{SD_{pooled}}$ & Small: 0.2, Medium: 0.5, Large: 0.8 \\
		Eta-squared ($\eta^2$) & 2.3025\% & $\frac{SS_{eff}}{SS_{total}}$ & Small: 1\%, Medium: 6\%, Large: 14\% \\
		Omega-squared ($\omega^2$) & 0.2797\% & $\frac{MS_{eff} - MS_{err}}{MS_{total} + MS_{err}}$ & Small: 1\%, Medium: 6\%, Large: 14\% \\
		\bottomrule
	\end{tabular}
	\\ \vspace{0.2cm}

\end{table}
\textbf{Variable Definitions:} $M_1$, $M_2$ = group means (INTM and UNIT); $SD_{pooled}$ = pooled standard deviation; $SS_{eff}$ = sum of squares for METHOD effect; $SS_{total}$ = total sum of squares; $MS_{eff}$ = mean square for METHOD effect; $MS_{err}$ = mean square for error; $MS_{total}$ = total mean square. Omega-squared is preferred over eta-squared as it provides less biased estimates of population effect size.

\subsection{Welch's t-Test Results for Pairwise Comparisons}

% --- Table A.6 (Welch t-Test) ---
\begin{table}[H]
	\centering
	\caption{Welch's t-Test Results for Pairwise Comparisons}
	\label{tab:a6}
	\small
	\begin{tabular}{l rrrrrr}
		\toprule
		\textbf{Comparison} & \textbf{Mean Diff} & \textbf{t-statistic} & \textbf{df} & \textbf{p-value} & \textbf{95\% CI Lower} & \textbf{95\% CI Upper} \\
		\midrule
		UNIT vs. INTM & -0.51 & -0.895 & 30.627 & 0.3777 & -1.676 & 0.654 \\
		UNIT vs. Tablet & 0.58 & 1.102 & 26.416 & 0.2802 & -0.500 & 1.660 \\
		INTM vs. Tablet & 1.09 & 2.659 & 34.572 & 0.0118 & 0.258 & 1.924 \\
		\bottomrule
	\end{tabular}
	\\ \vspace{0.2cm}
	\small Note: Mean differences calculated as (Group 1 Mean) - (Group 2 Mean). Negative values indicate Group 1 mean is lower than Group 2.
\end{table}

\subsection{Bootstrap Validation Results}

% --- Table A.7 (Bootstrap Validation) ---
\begin{table}[H]
	\centering
	\caption{Bootstrap Assessment of P-Value Reliability (1000 resamples)}
	\label{tab:a7}
	\small
	\begin{tabular}{l rrrr}
		\toprule
		\textbf{Comparison} & \textbf{Observed P} & \textbf{Bootstrap Mean} & \textbf{Bias} & \textbf{Std Error} \\
		\midrule
		UNIT vs. INTM & 0.3777 & 0.3744 & -0.0033 & 0.2942 \\
		UNIT vs. Tablet & 0.2802 & 0.3413 & 0.0610 & 0.2986 \\
		INTM vs. Tablet & 0.0118 & 0.0556 & 0.0438 & 0.1253 \\
		\bottomrule
	\end{tabular}
	\\ \vspace{0.2cm}
\end{table}

\textbf{Note:} Bootstrap Mean = average of 1000 bootstrap p-values; Bias = Bootstrap Mean - Observed P. Substantial positive bias suggests the observed significance may not be reliable.

\clearpage

\section{Appendix C: Client Question Analysis}


\subsection{Drum-to-Drum Variance Components}

Table \ref{tab:c1} presents the variance decomposition for tablet data using a random effects model with DRUM as a random intercept. The analysis partitions total variance into between-drum and within-drum components, providing insight into the consistency of the tablet production process.

% --- Table C.1 (Drum-to-Drum Variance) ---
\begin{table}[H]
	\centering
	\caption{Drum-to-Drum Variance Decomposition for Tablet Data}
	\label{tab:c1}
	\small
	\begin{tabular}{l r l}
		\toprule
		\textbf{Variance Component} & \textbf{Estimate} & \textbf{Interpretation} \\
		\midrule
		Between-Drum Variance & 0.4394 & Drum-to-drum variability \\
		Within-Drum (Residual) Variance & 1.3729 & Tablet-to-tablet variability \\
		\midrule
		Total Variance & 1.8123 & Sum of variance components \\
		\midrule
		Mean ASSAY & 35.82 mg/100mg & Overall tablet mean \\
		Drum Standard Deviation & 0.6629 mg/100mg & Between-drum SD \\
		Coefficient of Variation (CV) & 1.85\% & Relative variability \\
		\bottomrule
	\end{tabular}
	\\ \vspace{0.2cm}
	\footnotesize
	\textbf{Note:} Variance components estimated using REML (Restricted Maximum Likelihood) method with DRUM as random intercept. The low coefficient of variation (1.85\%) indicates excellent drum-to-drum consistency, contrasting favorably with the higher location-to-location variability (CV = 2.80\%) observed in the blending stage. Between-drum variance accounts for 24.2\% of total variance, with within-drum variance representing 75.8\%, indicating that tablet-to-tablet variation within drums is the dominant source of variability.
\end{table}

The low coefficient of variation indicates highly consistent drum-to-drum production performance, contrasting favorably with the higher location-to-location variability observed in the blending stage.

\subsection{Temporal Autocorrelation Analysis}

Two complementary approaches were employed to assess first-order temporal dependencies in tablet data: AR(1) covariance modeling and Durbin-Watson diagnostic testing.

\subsubsection{AR(1) Covariance Structure}

Table \ref{tab:c2} compares two candidate models: a baseline model assuming independence and a model incorporating AR(1) autocorrelation structure.

% --- Table C.2 (Model Comparison) ---
\begin{table}[H]
	\centering
	\caption{Model Comparison: Independence vs. AR(1) Covariance Structure}
	\label{tab:c2}
	\small
	\begin{tabular}{l c c c c c c}
		\toprule
		\textbf{Model} & \textbf{df} & \textbf{AIC} & \textbf{BIC} & \textbf{Test} & \textbf{L.Ratio} & \textbf{p-value} \\
		\midrule
		Independence (GLS) & 2 & \fbox{105.45} & \fbox{108.25} & --- & --- & --- \\
		AR(1) (GLS+Correlation) & 3 & 106.04 & 110.24 & 1 vs 2 & 1.412 & 0.235 \\
		\bottomrule
	\end{tabular}
	\\ \vspace{0.2cm}
	\footnotesize
	\textbf{Note:} Both models fitted using maximum likelihood (ML) estimation. The non-significant likelihood ratio test (p = 0.235 > 0.05) indicates that the AR(1) correlation structure does not provide a statistically significant improvement over the independence assumption. AIC and BIC values favor the simpler independence model (lower values indicate better fit). The estimated autocorrelation coefficient $\rho = 0.251$ indicates weak positive correlation between consecutive observations.
\end{table}

\subsubsection{Durbin-Watson Test}

Table \ref{tab:c3} presents the Durbin-Watson test results, a post-hoc diagnostic for detecting first-order autocorrelation in model residuals.

% --- Table C.3 (Durbin-Watson Test) ---
\begin{table}[H]
	\centering
	\caption{Durbin-Watson Test for First-Order Autocorrelation}
	\label{tab:c3}
	\small
	\begin{tabular}{l c}
		\toprule
		\textbf{Statistic} & \textbf{Value} \\
		\midrule
		DW Statistic & 1.565 \\
		p-value & 0.077 \\
		Alternative Hypothesis & True autocorrelation $>$ 0 \\
		\midrule
		Interpretation & No significant autocorrelation \\
		\bottomrule
	\end{tabular}
	\\ \vspace{0.2cm}
	\footnotesize
	\textbf{Note:} The Durbin-Watson statistic ranges from 0 to 4, with DW $\approx$ 2 indicating no autocorrelation. DW $<$ 2 suggests positive autocorrelation, while DW $>$ 2 suggests negative autocorrelation. The observed DW = 1.565 with p = 0.077 (not significant at $\alpha = 0.05$) indicates no substantial first-order autocorrelation in the tablet data. This corroborates the AR(1) model comparison results (Table \ref{tab:c2}), supporting the use of independence assumption for tablet-level quality monitoring.
\end{table}

\clearpage

\section{Appendix D: Software and Packages}

All analyses were conducted using R version 4.5.0 (2025-04-11) with the following packages:
\begin{itemize}
	\item \texttt{nlme} (version 3.1.168): Mixed-effects model fitting with heterogeneous variance
	\item \texttt{lmtest} (version 0.9.40): For Durbin-Watson test.
\end{itemize}

% --- DOCUMENT END ---
\end{document}